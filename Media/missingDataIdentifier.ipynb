{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49afb065-9fca-48dd-ab7b-fa48bf1c5808",
   "metadata": {},
   "source": [
    "# Identifying Missing Data\n",
    "\n",
    "This script aims to iterate through a data folder and identify missing parameter combinations, assuming that all combinatorial possibilities must be present\n",
    "\n",
    "## Parsing filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de621ef7-90a2-4dea-9b67-7449f937884a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: EndSim_epsM0.01_epsSD0.1___OpDnormal_OpM0_OpSD0.8___NetScale-free___NAgents1000___RS1__MedInfF0.5___MedDdeterministic-normal_MedN10_MedM0.75_MedSD0.1.csv\n",
      "Parsed: {'epsM': 0.01, 'epsSD': 0.1, 'OpD': 'normal', 'OpM': 0.0, 'OpSD': 0.8, 'NetworkType': 'Scale-free', 'NAgents': 1000, 'RandomSeed': 1, 'MedInfF': 0.5, 'MedD': 'deterministic-normal', 'MedN': 10, 'MedM': 0.75, 'MedSD': 0.1, 'Silence_Alpha': None, 'Silence_Tau': None, 'Silence_Delta0': None, 'SilenceByBoundary': None}\n",
      "\n",
      "Filename: EndSim_epsM0.01_epsSD0.1___OpDnormal_OpM0_OpSD0.8___NetScale-free___NAgents1000___RS1__MedInfF0.5___MedDdeterministic-normal_MedN10_MedM0.75_MedSD0.1_SA0.1_ST1_SDO0.75_SBBfalse.csv\n",
      "Parsed: {'epsM': 0.01, 'epsSD': 0.1, 'OpD': 'normal', 'OpM': 0.0, 'OpSD': 0.8, 'NetworkType': 'Scale-free', 'NAgents': 1000, 'RandomSeed': 1, 'MedInfF': 0.5, 'MedD': 'deterministic-normal', 'MedN': 10, 'MedM': 0.75, 'MedSD': 0.1, 'Silence_Alpha': 0.1, 'Silence_Tau': 1.0, 'Silence_Delta0': 0.75, 'SilenceByBoundary': False}\n",
      "\n",
      "Filename: EndSim_epsM0.01_epsSD0.1___OpDnormal_OpM0_OpSD0.8___NetScale-free___NAgents1000___RS1__MedInfF0.5___MedDdeterministic-normal_MedN10_MedM0.75_MedSD0.1_SA0.1_ST1_SDO-0.75_SBBtrue.csv\n",
      "Parsed: {'epsM': 0.01, 'epsSD': 0.1, 'OpD': 'normal', 'OpM': 0.0, 'OpSD': 0.8, 'NetworkType': 'Scale-free', 'NAgents': 1000, 'RandomSeed': 1, 'MedInfF': 0.5, 'MedD': 'deterministic-normal', 'MedN': 10, 'MedM': 0.75, 'MedSD': 0.1, 'Silence_Alpha': 0.1, 'Silence_Tau': 1.0, 'Silence_Delta0': -0.75, 'SilenceByBoundary': True}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "# no_silence_parsed_counts = 0 # Keeping track of which pattern was matched\n",
    "# silence_parsed_counts = 0 # Keeping track of which pattern was matched\n",
    "\n",
    "# Updated regex pattern to handle both old and new filename formats\n",
    "pattern = (\n",
    "    r\"EndSim_epsM(-?[\\d\\.]+)_epsSD(-?[\\d\\.]+)\"\n",
    "    r\"___OpD([a-zA-Z-]+)_OpM(-?[\\d\\.]+)_OpSD(-?[\\d\\.]+)\"\n",
    "    r\"___Net([a-zA-Z-]+)___NAgents(\\d+)___RS(\\d+)\"\n",
    "    r\"__MedInfF([\\d\\.]+)___MedD([a-zA-Z-]+)_MedN(\\d+)_MedM(-?[\\d\\.]+)_MedSD(-?[\\d\\.]+)\"\n",
    "    r\"(_SA(-?[\\d\\.]+)_ST(-?[\\d\\.]+)_SDO(-?[\\d\\.]+)_SBB([a-zA-Z]+))?\"\n",
    ")\n",
    "\n",
    "def parse_filename(filename):\n",
    "    \"\"\"Extract parameters from filename using regex with optional silence parameters\"\"\"\n",
    "    # Remove .csv extension before parsing\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "    match = re.search(pattern, base_name)\n",
    "    \n",
    "    if match:\n",
    "        result = {\n",
    "            # 'filename': filename,\n",
    "            'epsM': float(match.group(1)),\n",
    "            'epsSD': float(match.group(2)),\n",
    "            'OpD': match.group(3),\n",
    "            'OpM': float(match.group(4)),\n",
    "            'OpSD': float(match.group(5)),\n",
    "            'NetworkType': match.group(6),\n",
    "            'NAgents': int(match.group(7)),\n",
    "            'RandomSeed': int(match.group(8)),\n",
    "            'MedInfF': float(match.group(9)),\n",
    "            'MedD': match.group(10),\n",
    "            'MedN': int(match.group(11)),\n",
    "            'MedM': float(match.group(12)),\n",
    "            'MedSD': float(match.group(13))\n",
    "        }\n",
    "        # Check if silence parameters are present\n",
    "        if match.group(14):  # The entire silence block exists\n",
    "            # silence_parsed_counts = silence_parsed_counts + 1 # increment the silence parsed counter\n",
    "            result.update({\n",
    "                'Silence_Alpha': float(match.group(15)),\n",
    "                'Silence_Tau': float(match.group(16)),\n",
    "                'Silence_Delta0': float(match.group(17)),\n",
    "                'SilenceByBoundary': match.group(18).lower() == 'true'\n",
    "            })\n",
    "        else:\n",
    "            # no_silence_parsed_counts = no_silence_parsed_counts + 1\n",
    "            # Set default values for silence parameters if not present\n",
    "            result.update({\n",
    "                'Silence_Alpha': None,\n",
    "                'Silence_Tau': None,\n",
    "                'Silence_Delta0': None,\n",
    "                'SilenceByBoundary': None\n",
    "            })\n",
    "        \n",
    "        return result\n",
    "    return None\n",
    "\n",
    "# Test the parser\n",
    "test_filenames = [\n",
    "    \"EndSim_epsM0.01_epsSD0.1___OpDnormal_OpM0_OpSD0.8___NetScale-free___NAgents1000___RS1__MedInfF0.5___MedDdeterministic-normal_MedN10_MedM0.75_MedSD0.1.csv\",\n",
    "    \"EndSim_epsM0.01_epsSD0.1___OpDnormal_OpM0_OpSD0.8___NetScale-free___NAgents1000___RS1__MedInfF0.5___MedDdeterministic-normal_MedN10_MedM0.75_MedSD0.1_SA0.1_ST1_SDO0.75_SBBfalse.csv\",\n",
    "    \"EndSim_epsM0.01_epsSD0.1___OpDnormal_OpM0_OpSD0.8___NetScale-free___NAgents1000___RS1__MedInfF0.5___MedDdeterministic-normal_MedN10_MedM0.75_MedSD0.1_SA0.1_ST1_SDO-0.75_SBBtrue.csv\"\n",
    "]\n",
    "\n",
    "for filename in test_filenames:\n",
    "    params = parse_filename(filename)\n",
    "    print(f\"Filename: {filename}\")\n",
    "    print(f\"Parsed: {params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5dd5528f-e828-48b7-99b3-c7c8677cfec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not parse missing_simulations.csv\n",
      "Successfully parsed 102992/102993 files\n",
      "\n",
      "Files with silence parameters: 102992\n",
      "Files without silence parameters: 0\n",
      "File index without silence: (array([], dtype=int64),)\n",
      "\n",
      "epsM: 6 unique values\n",
      "  Values: [np.float64(0.01), np.float64(0.06), np.float64(0.11), np.float64(0.16), np.float64(0.21), np.float64(0.26)]\n",
      "\n",
      "epsSD: 4 unique values\n",
      "  Values: [np.float64(0.0), np.float64(0.05), np.float64(0.1), np.float64(0.15)]\n",
      "\n",
      "OpD: 1 unique values\n",
      "  Values: ['normal']\n",
      "\n",
      "OpM: 1 unique values\n",
      "  Values: [np.float64(0.0)]\n",
      "\n",
      "OpSD: 1 unique values\n",
      "  Values: [np.float64(0.8)]\n",
      "\n",
      "NetworkType: 1 unique values\n",
      "  Values: ['Scale-free']\n",
      "\n",
      "NAgents: 1 unique values\n",
      "  Values: [np.int64(1000)]\n",
      "\n",
      "MedInfF: 3 unique values\n",
      "  Values: [np.float64(0.0), np.float64(0.5), np.float64(1.0)]\n",
      "\n",
      "MedD: 1 unique values\n",
      "  Values: ['deterministic-normal']\n",
      "\n",
      "MedN: 1 unique values\n",
      "  Values: [np.int64(10)]\n",
      "\n",
      "MedM: 3 unique values\n",
      "  Values: [np.float64(-0.75), np.float64(0.0), np.float64(0.75)]\n",
      "\n",
      "MedSD: 4 unique values\n",
      "  Values: [np.float64(0.1), np.float64(0.4), np.float64(0.7), np.float64(1.0)]\n",
      "\n",
      "Silence_Alpha: 4 unique values\n",
      "  Values: [np.float64(0.1), np.float64(0.4), np.float64(0.7), np.float64(1.0)]\n",
      "\n",
      "Silence_Tau: 3 unique values\n",
      "  Values: [np.float64(1.0), np.float64(5.0), np.float64(9.0)]\n",
      "\n",
      "Silence_Delta0: 3 unique values\n",
      "  Values: [np.float64(-0.75), np.float64(0.0), np.float64(0.75)]\n",
      "\n",
      "SilenceByBoundary: 2 unique values\n",
      "  Values: [np.False_, np.True_]\n",
      "\n",
      "Expected total combinations: 124416\n",
      "Existing combinations: 102991\n",
      "Missing combinations: 21425\n",
      "\n",
      "=== MISSING COMBINATIONS ANALYSIS ===\n",
      "\n",
      "Missing combinations by parameter:\n",
      "\n",
      "epsM:\n",
      "  Missing: 6/6 values\n",
      "  Missing values: [np.float64(0.01), np.float64(0.06), np.float64(0.11), np.float64(0.16), np.float64(0.21), np.float64(0.26)]\n",
      "  Distribution of missing values:\n",
      "    0.26: 3799 combinations (17.7%)\n",
      "    0.16: 3537 combinations (16.5%)\n",
      "    0.06: 3536 combinations (16.5%)\n",
      "    0.21: 3522 combinations (16.4%)\n",
      "    0.11: 3519 combinations (16.4%)\n",
      "    0.01: 3512 combinations (16.4%)\n",
      "\n",
      "epsSD:\n",
      "  Missing: 4/4 values\n",
      "  Missing values: [np.float64(0.0), np.float64(0.05), np.float64(0.1), np.float64(0.15)]\n",
      "  Distribution of missing values:\n",
      "    0.15: 21048 combinations (98.2%)\n",
      "    0.0: 147 combinations (0.7%)\n",
      "    0.1: 129 combinations (0.6%)\n",
      "    0.05: 101 combinations (0.5%)\n",
      "\n",
      "OpM:\n",
      "  Missing: 1/1 values\n",
      "  Missing values: [np.int64(0)]\n",
      "  Distribution of missing values:\n",
      "    0: 21425 combinations (100.0%)\n",
      "\n",
      "OpSD:\n",
      "  Missing: 1/1 values\n",
      "  Missing values: [np.float64(0.8)]\n",
      "  Distribution of missing values:\n",
      "    0.8: 21425 combinations (100.0%)\n",
      "\n",
      "MedInfF:\n",
      "  Missing: 3/3 values\n",
      "  Missing values: [np.float64(0.0), np.float64(0.5), np.float64(1.0)]\n",
      "  Distribution of missing values:\n",
      "    1.0: 7189 combinations (33.6%)\n",
      "    0.5: 7130 combinations (33.3%)\n",
      "    0.0: 7106 combinations (33.2%)\n",
      "\n",
      "MedM:\n",
      "  Missing: 3/3 values\n",
      "  Missing values: [np.float64(-0.75), np.float64(0.0), np.float64(0.75)]\n",
      "  Distribution of missing values:\n",
      "    0.75: 10515 combinations (49.1%)\n",
      "    0.0: 10483 combinations (48.9%)\n",
      "    -0.75: 427 combinations (2.0%)\n",
      "\n",
      "MedSD:\n",
      "  Missing: 4/4 values\n",
      "  Missing values: [np.float64(0.1), np.float64(0.4), np.float64(0.7), np.float64(1.0)]\n",
      "  Distribution of missing values:\n",
      "    1.0: 5494 combinations (25.6%)\n",
      "    0.7: 5354 combinations (25.0%)\n",
      "    0.4: 5293 combinations (24.7%)\n",
      "    0.1: 5284 combinations (24.7%)\n",
      "\n",
      "Silence_Alpha:\n",
      "  Missing: 4/4 values\n",
      "  Missing values: [np.float64(0.1), np.float64(0.4), np.float64(0.7), np.float64(1.0)]\n",
      "  Distribution of missing values:\n",
      "    0.1: 5363 combinations (25.0%)\n",
      "    0.7: 5358 combinations (25.0%)\n",
      "    0.4: 5356 combinations (25.0%)\n",
      "    1.0: 5348 combinations (25.0%)\n",
      "\n",
      "Silence_Tau:\n",
      "  Missing: 3/3 values\n",
      "  Missing values: [np.int64(1), np.int64(5), np.int64(9)]\n",
      "  Distribution of missing values:\n",
      "    9: 7149 combinations (33.4%)\n",
      "    1: 7138 combinations (33.3%)\n",
      "    5: 7138 combinations (33.3%)\n",
      "\n",
      "Silence_Delta0:\n",
      "  Missing: 3/3 values\n",
      "  Missing values: [np.float64(-0.75), np.float64(0.0), np.float64(0.75)]\n",
      "  Distribution of missing values:\n",
      "    0.0: 7154 combinations (33.4%)\n",
      "    0.75: 7137 combinations (33.3%)\n",
      "    -0.75: 7134 combinations (33.3%)\n",
      "\n",
      "SilenceByBoundary:\n",
      "  Missing: 2/2 values\n",
      "  Missing values: [np.False_, np.True_]\n",
      "  Distribution of missing values:\n",
      "    False: 10721 combinations (50.0%)\n",
      "    True: 10704 combinations (50.0%)\n",
      "\n",
      "RandomSeed:\n",
      "  Missing: 2/2 values\n",
      "  Missing values: [np.int64(1), np.int64(2)]\n",
      "  Distribution of missing values:\n",
      "    2: 10871 combinations (50.7%)\n",
      "    1: 10554 combinations (49.3%)\n",
      "\n",
      "Missing combinations saved to: data/cluster/endsim/Step6_2reps\\missing_simulations.csv\n",
      "\n",
      "=== RECOMMENDATIONS FOR NEXT SIMULATIONS ===\n",
      "Priority: Focus on completing core parameter combinations:\n",
      "  epsM: [0.01 0.06 0.11 0.16 0.21 0.26]\n",
      "  epsSD: [0.   0.05 0.1  0.15]\n",
      "  OpM: [0]\n",
      "  OpSD: [0.8]\n",
      "\n",
      "Silence parameters needing completion:\n",
      "  Silence_Alpha: [1.  0.1 0.7 0.4]\n",
      "  Silence_Tau: [9 1 5]\n",
      "  Silence_Delta0: [-0.75  0.75  0.  ]\n",
      "  SilenceByBoundary: [False  True]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "\n",
    "fileofinterest = \"\"\n",
    "\n",
    "def analyze_simulation_coverage(directory):\n",
    "    \"\"\"Analyze which parameter combinations are missing from the simulation files\"\"\"\n",
    "    \n",
    "    # Get all CSV files in the directory\n",
    "    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "    \n",
    "    # Parse all files and collect parameters\n",
    "    all_params = []\n",
    "    valid_files = 0\n",
    "    \n",
    "    for filename in csv_files:\n",
    "        params = parse_filename(filename)\n",
    "        if params:\n",
    "            all_params.append(params)\n",
    "            valid_files += 1\n",
    "        else:\n",
    "            print(f\"Warning: Could not parse {filename}\")\n",
    "    \n",
    "    print(f\"Successfully parsed {valid_files}/{len(csv_files)} files\")\n",
    "    \n",
    "    if not all_params:\n",
    "        print(\"No valid files found!\")\n",
    "        return\n",
    "    \n",
    "    # Convert to DataFrame for easier analysis\n",
    "    df = pd.DataFrame(all_params)\n",
    "    \n",
    "    # Identify which files have silence parameters\n",
    "    has_silence_params = ~df['Silence_Alpha'].isna()\n",
    "    print(f\"\\nFiles with silence parameters: {has_silence_params.sum()}\")\n",
    "    print(f\"Files without silence parameters: {(~has_silence_params).sum()}\")\n",
    "    print(f\"File index without silence: {np.where(has_silence_params == False)}\")\n",
    "    # fileofinterest = (df.iloc[np.where(has_silence_params == False)]['filename'])\n",
    "    \n",
    "    # Get unique values for each parameter\n",
    "    unique_values = {}\n",
    "    for col in df.columns:\n",
    "        if col not in ['RandomSeed']:  # Exclude random seed from combination analysis\n",
    "            unique_vals = sorted(df[col].dropna().unique())\n",
    "            unique_values[col] = unique_vals\n",
    "            print(f\"\\n{col}: {len(unique_vals)} unique values\")\n",
    "            print(f\"  Values: {unique_vals}\")\n",
    "    \n",
    "    # Define the expected parameter combinations (your simulation design)\n",
    "    # Adjust these ranges based on your intended experimental design\n",
    "    expected_combinations = {\n",
    "        'epsM': [0.01, 0.06, 0.11, 0.16, 0.21, 0.26],\n",
    "        'epsSD': [0, 0.05, 0.1, 0.15],\n",
    "        'OpM': [0],\n",
    "        'OpSD': [0.8],\n",
    "        'MedInfF': [0, 0.5, 1],\n",
    "        'MedM': [-0.75, 0, 0.75],\n",
    "        'MedSD': [0.1, 0.4, 0.7, 1],\n",
    "        'Silence_Alpha': [0.1, 0.4, 0.7, 1],\n",
    "        'Silence_Tau': [1, 5, 9],\n",
    "        'Silence_Delta0': [-0.75, 0, 0.75],\n",
    "        'SilenceByBoundary': [True, False],\n",
    "        'RandomSeed': [1, 2]\n",
    "    }\n",
    "    \n",
    "    # Filter expected combinations to only include parameters that exist in your data\n",
    "    actual_expected = {}\n",
    "    for param, values in expected_combinations.items():\n",
    "        if param in df.columns:\n",
    "            # Only include values that are relevant (non-NaN values in data)\n",
    "            if param in ['Silence_Alpha', 'Silence_Tau', 'Silence_Delta0', 'SilenceByBoundary']:\n",
    "                # For silence parameters, check if they exist in any file\n",
    "                if has_silence_params.any():\n",
    "                    actual_expected[param] = values\n",
    "            else:\n",
    "                actual_expected[param] = values\n",
    "    \n",
    "    # Generate all possible combinations\n",
    "    param_names = list(actual_expected.keys())\n",
    "    all_possible_combinations = list(product(*[actual_expected[name] for name in param_names]))\n",
    "    \n",
    "    print(f\"\\nExpected total combinations: {len(all_possible_combinations)}\")\n",
    "    \n",
    "    # Check which combinations exist\n",
    "    existing_combinations = set()\n",
    "    for _, row in df.iterrows():\n",
    "        combo = tuple(row[param] if pd.notna(row[param]) else None for param in param_names)\n",
    "        existing_combinations.add(combo)\n",
    "    \n",
    "    print(f\"Existing combinations: {len(existing_combinations)}\")\n",
    "    print(f\"Missing combinations: {len(all_possible_combinations) - len(existing_combinations)}\")\n",
    "    \n",
    "    # Identify missing combinations\n",
    "    missing_combinations = []\n",
    "    for combo in all_possible_combinations:\n",
    "        if combo not in existing_combinations:\n",
    "            missing_combinations.append(dict(zip(param_names, combo)))\n",
    "    \n",
    "    # Analyze missing combinations by parameter\n",
    "    print(\"\\n=== MISSING COMBINATIONS ANALYSIS ===\")\n",
    "    \n",
    "    if missing_combinations:\n",
    "        missing_df = pd.DataFrame(missing_combinations)\n",
    "        \n",
    "        print(\"\\nMissing combinations by parameter:\")\n",
    "        for param in param_names:\n",
    "            missing_count = len(missing_df)\n",
    "            total_expected = len(actual_expected[param])\n",
    "            missing_values = missing_df[param].unique()\n",
    "            \n",
    "            print(f\"\\n{param}:\")\n",
    "            print(f\"  Missing: {len(missing_values)}/{total_expected} values\")\n",
    "            print(f\"  Missing values: {sorted(missing_values)}\")\n",
    "            \n",
    "            # Show which specific values are most missing\n",
    "            value_counts = missing_df[param].value_counts()\n",
    "            print(f\"  Distribution of missing values:\")\n",
    "            for value, count in value_counts.items():\n",
    "                percentage = (count / len(missing_df)) * 100\n",
    "                print(f\"    {value}: {count} combinations ({percentage:.1f}%)\")\n",
    "    \n",
    "        # Save missing combinations to CSV for reference\n",
    "        missing_df.to_csv(os.path.join(directory, 'missing_simulations.csv'), index=False)\n",
    "        print(f\"\\nMissing combinations saved to: {os.path.join(directory, 'missing_simulations.csv')}\")\n",
    "        \n",
    "        # Generate a summary of what to run next\n",
    "        print(\"\\n=== RECOMMENDATIONS FOR NEXT SIMULATIONS ===\")\n",
    "        \n",
    "        # Find the most critical missing parameters\n",
    "        critical_params = []\n",
    "        for param in ['epsM', 'epsSD', 'OpM', 'OpSD']:  # Core parameters\n",
    "            if param in param_names:\n",
    "                missing_vals = missing_df[param].unique()\n",
    "                if len(missing_vals) > 0:\n",
    "                    critical_params.append((param, missing_vals))\n",
    "        \n",
    "        if critical_params:\n",
    "            print(\"Priority: Focus on completing core parameter combinations:\")\n",
    "            for param, values in critical_params:\n",
    "                print(f\"  {param}: {values}\")\n",
    "        \n",
    "        # Check if silence parameters need completion\n",
    "        silence_params = ['Silence_Alpha', 'Silence_Tau', 'Silence_Delta0', 'SilenceByBoundary']\n",
    "        missing_silence = [p for p in silence_params if p in param_names and len(missing_df[p].unique()) > 0]\n",
    "        \n",
    "        if missing_silence:\n",
    "            print(\"\\nSilence parameters needing completion:\")\n",
    "            for param in missing_silence:\n",
    "                missing_vals = missing_df[param].unique()\n",
    "                print(f\"  {param}: {missing_vals}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"All expected combinations are present! 🎉\")\n",
    "    \n",
    "    return df, missing_combinations\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    directory_path = \"data/cluster/endsim/Step6_2reps\"\n",
    "    df, missing = analyze_simulation_coverage(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1481224-683e-4af2-9736-bed6e07edc70",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'has_silence_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mhas_silence_params\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'has_silence_params' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcaa06e-aa74-4127-8e6b-de9b56a50462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a763d8f7-05ef-43c7-ae06-369e8a5be78c",
   "metadata": {},
   "source": [
    "## Expected combinations\n",
    "\n",
    "```    \n",
    "expected_combinations = {\n",
    "        'epsM': [0.01, 0.06, 0.11, 0.16, 0.21, 0.26],\n",
    "        'epsSD': [0.05, 0.1, 0.15],\n",
    "        'OpM': [0],\n",
    "        'OpSD': [0.8],\n",
    "        'MedInfF': [0, 0.5, 1],\n",
    "        'MedM': [-0.75, 0, 0.75],\n",
    "        'MedSD': [0.1, 0.4, 0.7, 1],\n",
    "        'Silence_Alpha': [0.1, 0.4, 0.7, 1],\n",
    "        'Silence_Tau': [1, 5, 9],\n",
    "        'Silence_Delta0': [-0.75, 0, 0.75],\n",
    "        'SilenceByBoundary': [True, False]\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0cd2ef-3a02-4bfd-9a5c-a926600d165e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
